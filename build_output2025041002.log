#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 694B done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
#2 ERROR: failed to do request: Head "https://registry.docker-cn.com/v2/nvidia/cuda/manifests/12.1.0-cudnn8-runtime-ubuntu22.04?ns=docker.io": dial tcp 106.14.52.175:443: i/o timeout
------
 > [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04:
------
Dockerfile:2
--------------------
   1 |     # 基于 NVIDIA CUDA 镜像（假设你要运行 PyTorch 和 vLLM）
   2 | >>> FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
   3 |     
   4 |     # 安装系统依赖
--------------------
ERROR: failed to solve: DeadlineExceeded: DeadlineExceeded: DeadlineExceeded: nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04: failed to resolve source metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04: failed to do request: Head "https://registry.docker-cn.com/v2/nvidia/cuda/manifests/12.1.0-cudnn8-runtime-ubuntu22.04?ns=docker.io": dial tcp 106.14.52.175:443: i/o timeout
